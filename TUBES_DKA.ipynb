{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Network Intrusion Detection"
      ],
      "metadata": {
        "id": "eUwl5ZNwFZkG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Muhammad Irgiansyah (103012300039)\")\n",
        "print(\"Bill Stephen Sembiring (103012330197)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kSHvJzO8Fs7E",
        "outputId": "d8339afc-169f-438b-f26d-bd2a16f84702"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Muhammad Irgiansyah (103012300039)\n",
            "Bill Stephen Sembiring (103012330197)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "KNN"
      ],
      "metadata": {
        "id": "6cAYkVtCzKLy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, precision_score, recall_score, f1_score\n",
        "from scipy.stats import wilcoxon\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# === 1. Load dan Bersihkan Data ===\n",
        "df = pd.read_csv('D:/Telkom/Semester 4/DKA/tubes/Test_data.csv')\n",
        "df.replace('?', np.nan, inplace=True)\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "# === 2. Pilih Fitur Penting ===\n",
        "selected_features = ['duration', 'protocol_type', 'service', 'flag',\n",
        "                     'src_bytes', 'dst_bytes', 'count', 'srv_count']\n",
        "df = df[selected_features].copy()\n",
        "\n",
        "# === 3. Label Biner (Normal vs Intrusion) ===\n",
        "df['binary_label'] = df['src_bytes'].astype(int).apply(lambda x: 0 if x <= 500 else 1)\n",
        "\n",
        "# === 4. Encode Fitur Kategorikal ===\n",
        "cat_cols = ['protocol_type', 'service', 'flag']\n",
        "for col in cat_cols:\n",
        "    le = LabelEncoder()\n",
        "    df[col] = le.fit_transform(df[col])\n",
        "\n",
        "# === 5. Normalisasi untuk scoring klasifikasi multi-kelas ===\n",
        "scaler_temp = MinMaxScaler()\n",
        "df[['duration', 'src_bytes', 'dst_bytes', 'count', 'srv_count']] = scaler_temp.fit_transform(\n",
        "    df[['duration', 'src_bytes', 'dst_bytes', 'count', 'srv_count']]\n",
        ")\n",
        "\n",
        "# === 6. Tambah Label Multi-Kelas Berdasarkan Skor dan dst_bytes ===\n",
        "def compute_score(row):\n",
        "    score = (\n",
        "        row['duration'] * 0.2 +\n",
        "        row['src_bytes'] * 0.2 +\n",
        "        row['dst_bytes'] * 0.2 +\n",
        "        row['count'] * 0.2 +\n",
        "        row['srv_count'] * 0.2\n",
        "    ) * 100\n",
        "    return score\n",
        "\n",
        "def classify(score, dst_bytes):\n",
        "    if score <= 30:\n",
        "        return 'Normal'\n",
        "    elif score <= 60:\n",
        "        return 'Probe'\n",
        "    elif score <= 80:\n",
        "        return 'R2L'\n",
        "    else:\n",
        "        return 'DoS' if dst_bytes > 0.5 else 'U2R'\n",
        "\n",
        "def run_knn_cv(X, y, n_splits=5):\n",
        "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "    all_probas = []\n",
        "    start_time = time.time()\n",
        "\n",
        "    for train_i, test_i in skf.split(X, y):\n",
        "        Xtr, Xte = X.iloc[train_i], X.iloc[test_i]\n",
        "        ytr, yte = y.iloc[train_i], y.iloc[test_i]\n",
        "\n",
        "        best_k, best_acc = 1, 0\n",
        "        for k in range(1, 11):\n",
        "            model = KNeighborsClassifier(n_neighbors=k).fit(Xtr, ytr)\n",
        "            acc = accuracy_score(yte, model.predict(Xte))\n",
        "            if acc > best_acc:\n",
        "                best_k, best_acc = k, acc\n",
        "\n",
        "        knn_best = KNeighborsClassifier(n_neighbors=best_k).fit(Xtr, ytr)\n",
        "        probas = knn_best.predict_proba(Xte)[:, 1]\n",
        "        all_probas.extend(probas)\n",
        "\n",
        "    end_time = time.time()\n",
        "    elapsed = end_time - start_time\n",
        "    return np.array(all_probas), elapsed\n",
        "\n",
        "\n",
        "df['score'] = df.apply(compute_score, axis=1)\n",
        "df['attack_type'] = df.apply(lambda row: classify(row['score'], row['dst_bytes']), axis=1)\n",
        "\n",
        "# === Upper Scaling: Batasi 1000 data pertama ===\n",
        "df = df.head(1000).copy()\n",
        "\n",
        "# === 7. Pisahkan Fitur dan Label ===\n",
        "X = df.drop(['binary_label', 'attack_type', 'score'], axis=1)\n",
        "y_bin = df['binary_label']\n",
        "y_multi = df['attack_type']\n",
        "\n",
        "# === 8. Split Data 80:20 ===\n",
        "X_train_bin, X_test_bin, y_train_bin, y_test_bin = train_test_split(X, y_bin, test_size=0.2, random_state=42)\n",
        "X_train_multi, X_test_multi, y_train_multi, y_test_multi = train_test_split(X, y_multi, test_size=0.2, random_state=42)\n",
        "\n",
        "# === 9. Normalisasi Fitur Numerik ===\n",
        "numeric_cols = ['duration', 'src_bytes', 'dst_bytes', 'count', 'srv_count']\n",
        "scaler = MinMaxScaler()\n",
        "X_train_bin[numeric_cols] = scaler.fit_transform(X_train_bin[numeric_cols])\n",
        "X_test_bin[numeric_cols] = scaler.transform(X_test_bin[numeric_cols])\n",
        "X_train_multi[numeric_cols] = scaler.fit_transform(X_train_multi[numeric_cols])\n",
        "X_test_multi[numeric_cols] = scaler.transform(X_test_multi[numeric_cols])\n",
        "\n",
        "# === 10. Evaluasi Nilai k Terbaik ===\n",
        "k_values = list(range(1, 11))\n",
        "acc_scores = []\n",
        "for k in k_values:\n",
        "    model = KNeighborsClassifier(n_neighbors=k)\n",
        "    model.fit(X_train_bin, y_train_bin)\n",
        "    pred = model.predict(X_test_bin)\n",
        "    acc_scores.append(accuracy_score(y_test_bin, pred))\n",
        "optimal_k = k_values[np.argmax(acc_scores)]\n",
        "print(f\"Nilai k optimal: {optimal_k} (Akurasi: {acc_scores[np.argmax(acc_scores)]:.4f})\")\n",
        "\n",
        "print(\"\\n=== Evaluasi Akurasi untuk Setiap Nilai k ===\")\n",
        "for i, k in enumerate(k_values):\n",
        "    print(f\"k = {k}: Akurasi = {acc_scores[i]:.4f}\")\n",
        "\n",
        "# === 11. Klasifikasi Biner dengan K Optimal ===\n",
        "knn_bin = KNeighborsClassifier(n_neighbors=optimal_k)\n",
        "knn_bin.fit(X_train_bin, y_train_bin)\n",
        "\n",
        "# === Evaluasi pada Data Training ===\n",
        "y_train_pred_bin = knn_bin.predict(X_train_bin)\n",
        "train_acc_bin = accuracy_score(y_train_bin, y_train_pred_bin)\n",
        "train_prec_bin = precision_score(y_train_bin, y_train_pred_bin, zero_division=0)\n",
        "train_rec_bin = recall_score(y_train_bin, y_train_pred_bin, zero_division=0)\n",
        "train_f1_bin = f1_score(y_train_bin, y_train_pred_bin, zero_division=0)\n",
        "print(f\"\\n[Training]     Akurasi: {train_acc_bin:.4f} | Precision: {train_prec_bin:.4f} | Recall: {train_rec_bin:.4f} | F1-score: {train_f1_bin:.4f}\")\n",
        "# Confusion Matrix - Data Training\n",
        "print(\"\\n=== Evaluasi Klasifikasi Biner - Training ===\")\n",
        "print(f\"Akurasi: {train_acc_bin:.4f}\")\n",
        "print(\"Classification Report:\\n\", classification_report(y_train_bin, y_train_pred_bin))\n",
        "cm_train = confusion_matrix(y_train_bin, y_train_pred_bin)\n",
        "plt.figure(figsize=(5, 4))\n",
        "sns.heatmap(cm_train, annot=True, fmt='d', cmap='Oranges',\n",
        "            xticklabels=['Normal', 'Intrusion'], yticklabels=['Normal', 'Intrusion'])\n",
        "plt.title(\"Confusion Matrix - Data Training\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# === Evaluasi pada Data Uji (Testing) ===\n",
        "y_test_pred_bin = knn_bin.predict(X_test_bin)\n",
        "test_acc_bin = accuracy_score(y_test_bin, y_test_pred_bin)\n",
        "test_prec_bin = precision_score(y_test_bin, y_test_pred_bin, zero_division=0)\n",
        "test_rec_bin = recall_score(y_test_bin, y_test_pred_bin, zero_division=0)\n",
        "test_f1_bin = f1_score(y_test_bin, y_test_pred_bin, zero_division=0)\n",
        "print(f\"[Testing]      Akurasi: {test_acc_bin:.4f} | Precision: {test_prec_bin:.4f} | Recall: {test_rec_bin:.4f} | F1-score: {test_f1_bin:.4f}\")\n",
        "# Confusion Matrix - Data Testing\n",
        "print(\"\\n=== Evaluasi Klasifikasi Biner - Testing ===\")\n",
        "print(f\"Akurasi: {test_acc_bin:.4f}\")\n",
        "print(\"Classification Report:\\n\", classification_report(y_test_bin, y_test_pred_bin))\n",
        "cm_test = confusion_matrix(y_test_bin, y_test_pred_bin)\n",
        "plt.figure(figsize=(5, 4))\n",
        "sns.heatmap(cm_test, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=['Normal', 'Intrusion'], yticklabels=['Normal', 'Intrusion'])\n",
        "plt.title(\"Confusion Matrix - Data Testing\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# === Evaluasi pada Seluruh Data Gabungan ===\n",
        "X_all_bin = pd.concat([X_train_bin, X_test_bin])\n",
        "y_all_bin = pd.concat([y_train_bin, y_test_bin])\n",
        "y_all_pred_bin = knn_bin.predict(X_all_bin)\n",
        "all_acc_bin = accuracy_score(y_all_bin, y_all_pred_bin)\n",
        "all_prec_bin = precision_score(y_all_bin, y_all_pred_bin, zero_division=0)\n",
        "all_rec_bin = recall_score(y_all_bin, y_all_pred_bin, zero_division=0)\n",
        "all_f1_bin = f1_score(y_all_bin, y_all_pred_bin, zero_division=0)\n",
        "print(f\"[Keseluruhan]  Akurasi: {all_acc_bin:.4f} | Precision: {all_prec_bin:.4f} | Recall: {all_rec_bin:.4f} | F1-score: {all_f1_bin:.4f}\")\n",
        "# Confusion Matrix - Seluruh Data\n",
        "print(\"\\n=== Evaluasi Klasifikasi Biner - Keseluruhan ===\")\n",
        "print(f\"Akurasi: {all_acc_bin:.4f}\")\n",
        "print(\"Classification Report:\\n\", classification_report(y_all_bin, y_all_pred_bin))\n",
        "cm_all = confusion_matrix(y_all_bin, y_all_pred_bin)\n",
        "plt.figure(figsize=(5, 4))\n",
        "sns.heatmap(cm_all, annot=True, fmt='d', cmap='Greens',\n",
        "            xticklabels=['Normal', 'Intrusion'], yticklabels=['Normal', 'Intrusion'])\n",
        "plt.title(\"Confusion Matrix - Seluruh Data\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# === 12. Klasifikasi Multi-Kelas ===\n",
        "knn_multi = KNeighborsClassifier(n_neighbors=optimal_k)\n",
        "knn_multi.fit(X_train_multi, y_train_multi)\n",
        "\n",
        "# Tentukan semua label unik yang mungkin muncul dalam dataset\n",
        "labels_multi = sorted(df['attack_type'].unique())\n",
        "\n",
        "# === Evaluasi pada Data Training (Multi-Kelas) ===\n",
        "y_train_pred_multi = knn_multi.predict(X_train_multi)\n",
        "train_acc_multi = accuracy_score(y_train_multi, y_train_pred_multi)\n",
        "print(\"\\n=== Evaluasi Klasifikasi Multi-Kelas - Training ===\")\n",
        "print(f\"Akurasi: {train_acc_multi:.4f}\")\n",
        "print(\"Classification Report:\\n\", classification_report(y_train_multi, y_train_pred_multi, labels=labels_multi))\n",
        "cm_train_multi = confusion_matrix(y_train_multi, y_train_pred_multi, labels=labels_multi)\n",
        "plt.figure(figsize=(6, 5))\n",
        "sns.heatmap(cm_train_multi, annot=True, fmt='d', cmap='Oranges',\n",
        "            xticklabels=labels_multi,\n",
        "            yticklabels=labels_multi)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Confusion Matrix - Multi-Kelas Training')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# === Evaluasi pada Data Testing (Multi-Kelas) ===\n",
        "y_test_pred_multi = knn_multi.predict(X_test_multi)\n",
        "test_acc_multi = accuracy_score(y_test_multi, y_test_pred_multi)\n",
        "print(\"\\n=== Evaluasi Klasifikasi Multi-Kelas - Testing ===\")\n",
        "print(f\"Akurasi: {test_acc_multi:.4f}\")\n",
        "print(\"Classification Report:\\n\", classification_report(y_test_multi, y_test_pred_multi, labels=labels_multi))\n",
        "cm_test_multi = confusion_matrix(y_test_multi, y_test_pred_multi, labels=labels_multi)\n",
        "plt.figure(figsize=(6, 5))\n",
        "sns.heatmap(cm_test_multi, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=labels_multi,\n",
        "            yticklabels=labels_multi)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Confusion Matrix - Multi-Kelas Testing')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# === Evaluasi pada Seluruh Data Gabungan (Multi-Kelas) ===\n",
        "X_all_multi = pd.concat([X_train_multi, X_test_multi])\n",
        "y_all_multi = pd.concat([y_train_multi, y_test_multi])\n",
        "y_all_pred_multi = knn_multi.predict(X_all_multi)\n",
        "all_acc_multi = accuracy_score(y_all_multi, y_all_pred_multi)\n",
        "print(\"\\n=== Evaluasi Klasifikasi Multi-Kelas - Keseluruhan ===\")\n",
        "print(f\"Akurasi: {all_acc_multi:.4f}\")\n",
        "print(\"Classification Report:\\n\", classification_report(y_all_multi, y_all_pred_multi, labels=labels_multi))\n",
        "cm_all_multi = confusion_matrix(y_all_multi, y_all_pred_multi, labels=labels_multi)\n",
        "plt.figure(figsize=(6, 5))\n",
        "sns.heatmap(cm_all_multi, annot=True, fmt='d', cmap='Greens',\n",
        "            xticklabels=labels_multi,\n",
        "            yticklabels=labels_multi)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Confusion Matrix - Multi-Kelas Keseluruhan')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# === Contoh Hasil Prediksi Multi-Kelas ===\n",
        "y_pred_multi = knn_multi.predict(X_test_multi)\n",
        "\n",
        "results_df = pd.DataFrame({\n",
        "    'Actual': y_test_multi,\n",
        "    'Predicted': y_pred_multi\n",
        "})\n",
        "print(\"\\n=== Contoh Hasil Prediksi Multi-Kelas ===\")\n",
        "print(results_df.head(10))\n",
        "\n",
        "pd.Series(y_pred_multi).value_counts().plot(kind='pie', autopct='%1.1f%%', startangle=140, figsize=(6, 6))\n",
        "plt.title(\"Distribusi Prediksi KNN (Multi-Kelas)\")\n",
        "plt.ylabel('')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# === Evaluasi Beberapa Split Data ===\n",
        "split_ratios = [0.1, 0.2, 0.3, 0.4, 0.5]\n",
        "print(\"\\n=== Evaluasi Akurasi Berbagai Split Data ===\")\n",
        "for ratio in split_ratios:\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y_bin, test_size=ratio, random_state=42)\n",
        "    X_train[numeric_cols] = scaler.fit_transform(X_train[numeric_cols])\n",
        "    X_test[numeric_cols] = scaler.transform(X_test[numeric_cols])\n",
        "    model = KNeighborsClassifier(n_neighbors=3)\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    print(f\"Split {int((1-ratio)*100)}:{int(ratio*100)} - Akurasi: {acc:.4f}\")\n",
        "\n",
        "# === Augmentasi Data dan Wilcoxon Test (dengan noise ringan) ===\n",
        "df_aug = df.copy()\n",
        "indices_to_modify = np.random.choice(df_aug.index, size=int(0.05 * len(df_aug)), replace=False)\n",
        "df_aug.loc[indices_to_modify, 'src_bytes'] += np.random.normal(loc=0, scale=10, size=len(indices_to_modify))\n",
        "\n",
        "print(f\"\\nData dimodifikasi secara acak pada {len(indices_to_modify)} baris (augmentasi dengan noise ringan)\")\n",
        "\n",
        "original = df['src_bytes'].loc[indices_to_modify].copy()\n",
        "augmented = df_aug['src_bytes'].loc[indices_to_modify].copy()\n",
        "\n",
        "if len(original) == len(augmented):\n",
        "    stat, p = wilcoxon(original, augmented)\n",
        "    print(f\"\\nWilcoxon test untuk src_bytes: statistic = {stat:.4f}, p-value = {p:.4f}\")\n",
        "else:\n",
        "    print(\"\\nTidak cukup data sepadan untuk Wilcoxon test.\")\n",
        "\n",
        "# === Blok Diagram KNN ===\n",
        "# Create block diagram for KNN classification pipeline\n",
        "fig, ax = plt.subplots(figsize=(10, 3))\n",
        "ax.set_axis_off()\n",
        "\n",
        "# Define block positions and labels\n",
        "blocks = [\n",
        "    (\"Raw Data\\nLoad & Clean\", 0.1),\n",
        "    (\"Encode & Scale\\nFeatures\", 0.3),\n",
        "    (\"Split Data\\nTrain/Test\", 0.5),\n",
        "    (\"KNN Model\\nTraining & Inference\", 0.7),\n",
        "    (\"Evaluation\\nMetrics & Output\", 0.9),\n",
        "]\n",
        "\n",
        "# Draw blocks and arrows\n",
        "width, height = 0.15, 0.2\n",
        "for label, x in blocks:\n",
        "    rect = Rectangle((x - width/2, 0.4), width, height, fill=False)\n",
        "    ax.add_patch(rect)\n",
        "    ax.text(x, 0.5, label, ha='center', va='center')\n",
        "# Draw arrows between blocks\n",
        "for i in range(len(blocks) - 1):\n",
        "    x_start = blocks[i][1] + width/2\n",
        "    x_end = blocks[i+1][1] - width/2\n",
        "    ax.annotate(\"\",\n",
        "                xy=(x_end, 0.5), xytext=(x_start, 0.5),\n",
        "                arrowprops=dict(arrowstyle='->'))\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371
        },
        "id": "T6Edcj2lqI5k",
        "outputId": "ebc2c95e-8a3d-41a8-b894-49fce5e68a4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'D:\\\\MATERI KULIAH\\\\Semester 4\\\\Dasar Kecerdasan Artifisial\\\\Tubes\\\\Test_data.csv\\\\Test_data.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-fb054b66785b>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# === 1. Load dan Bersihkan Data ===\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'D:\\MATERI KULIAH\\Semester 4\\Dasar Kecerdasan Artifisial\\Tubes\\Test_data.csv\\Test_data.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'?'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'D:\\\\MATERI KULIAH\\\\Semester 4\\\\Dasar Kecerdasan Artifisial\\\\Tubes\\\\Test_data.csv\\\\Test_data.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "FUZZY MAMDANI"
      ],
      "metadata": {
        "id": "__MRDpylzOIF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import skfuzzy as fuzz\n",
        "from skfuzzy import control as ctrl\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix,classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy.stats import wilcoxon\n",
        "from matplotlib.patches import Rectangle\n",
        "\n",
        "# Load dataset\n",
        "_df_fuzzy = pd.read_csv('D:/Telkom/Semester 4/DKA/tubes/Test_data.csv')\n",
        "_df_fuzzy.replace('?', np.nan, inplace=True)\n",
        "_df_fuzzy.dropna(inplace=True)\n",
        "\n",
        "# Memastikan serror_rate tersedia\n",
        "if 'serror_rate' not in _df_fuzzy.columns:\n",
        "    if 'dst_host_serror_rate' in _df_fuzzy.columns:\n",
        "        _df_fuzzy['serror_rate_fuzzy'] = _df_fuzzy['dst_host_serror_rate']\n",
        "    else:\n",
        "        _df_fuzzy['serror_rate_fuzzy'] = 0.0\n",
        "else:\n",
        "    _df_fuzzy['serror_rate_fuzzy'] = _df_fuzzy['serror_rate']\n",
        "\n",
        "# Fitur yang digunakan\n",
        "_features_fuzzy = ['duration', 'src_bytes', 'dst_bytes', 'count', 'serror_rate_fuzzy']\n",
        "\n",
        "# Sampling dan normalisasi\n",
        "_scaler_fuzzy = MinMaxScaler()\n",
        "_df_sample_fuzzy = _df_fuzzy.sample(n=1000, random_state=42).reset_index(drop=True)\n",
        "_X_fuzzy_norm = pd.DataFrame(_scaler_fuzzy.fit_transform(_df_sample_fuzzy[_features_fuzzy]), columns=_features_fuzzy)\n",
        "\n",
        "# Split train/test\n",
        "_X_train_fuzzy, _X_test_fuzzy, _idx_train_fuzzy, _idx_test_fuzzy = train_test_split(\n",
        "    _X_fuzzy_norm, _df_sample_fuzzy.index, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Variabel fuzzy dengan batas ideal berdasarkan statistik fitur\n",
        "_duration_fuzzy = ctrl.Antecedent(np.arange(0, 1.01, 0.01), 'duration')\n",
        "_duration_fuzzy['low']    = fuzz.trimf(_duration_fuzzy.universe, [0,    0,   0.1])\n",
        "_duration_fuzzy['medium'] = fuzz.trimf(_duration_fuzzy.universe, [0.05, 0.25,0.5])\n",
        "_duration_fuzzy['high']   = fuzz.trapmf(_duration_fuzzy.universe, [0.4,  0.7, 1,   1])\n",
        "_duration_fuzzy.view()\n",
        "\n",
        "_src_bytes_fuzzy = ctrl.Antecedent(np.arange(0, 1.01, 0.01), 'src_bytes')\n",
        "_src_bytes_fuzzy['low']    = fuzz.trimf(_src_bytes_fuzzy.universe, [0,    0,   0.2])\n",
        "_src_bytes_fuzzy['medium'] = fuzz.trimf(_src_bytes_fuzzy.universe, [0.1,  0.4, 0.7])\n",
        "_src_bytes_fuzzy['high']   = fuzz.trapmf(_src_bytes_fuzzy.universe, [0.6,  0.8, 1,   1])\n",
        "_src_bytes_fuzzy.view()\n",
        "\n",
        "_dst_bytes_fuzzy = ctrl.Antecedent(np.arange(0, 1.01, 0.01), 'dst_bytes')\n",
        "_dst_bytes_fuzzy['low']    = fuzz.trimf(_dst_bytes_fuzzy.universe, [0,    0,   0.2])\n",
        "_dst_bytes_fuzzy['medium'] = fuzz.trimf(_dst_bytes_fuzzy.universe, [0.1,  0.5, 0.8])\n",
        "_dst_bytes_fuzzy['high']   = fuzz.trapmf(_dst_bytes_fuzzy.universe, [0.7,  0.9, 1,   1])\n",
        "_dst_bytes_fuzzy.view()\n",
        "\n",
        "_count_fuzzy = ctrl.Antecedent(np.arange(0, 1.01, 0.01), 'count')\n",
        "_count_fuzzy['low']    = fuzz.trimf(_count_fuzzy.universe, [0,    0,   0.3])\n",
        "_count_fuzzy['medium'] = fuzz.trimf(_count_fuzzy.universe, [0.2,  0.6, 0.85])\n",
        "_count_fuzzy['high']   = fuzz.trapmf(_count_fuzzy.universe, [0.75, 0.9, 1,   1])\n",
        "_count_fuzzy.view()\n",
        "\n",
        "_serror_rate_fuzzy = ctrl.Antecedent(np.arange(0, 1.01, 0.01), 'serror_rate_fuzzy')\n",
        "_serror_rate_fuzzy['low']    = fuzz.trimf(_serror_rate_fuzzy.universe, [0,    0,   0.1])\n",
        "_serror_rate_fuzzy['medium'] = fuzz.trimf(_serror_rate_fuzzy.universe, [0.05, 0.4, 0.7])\n",
        "_serror_rate_fuzzy['high']   = fuzz.trapmf(_serror_rate_fuzzy.universe, [0.6,  0.8, 1,   1])\n",
        "_serror_rate_fuzzy.view()\n",
        "\n",
        "_intrusion_level_fuzzy = ctrl.Consequent(np.arange(0, 101, 1), 'intrusion_level_fuzzy')\n",
        "_intrusion_level_fuzzy['normal']     = fuzz.trimf(_intrusion_level_fuzzy.universe, [0,  0,  30])\n",
        "_intrusion_level_fuzzy['suspicious'] = fuzz.trimf(_intrusion_level_fuzzy.universe, [20, 50, 80])\n",
        "_intrusion_level_fuzzy['intrusion']  = fuzz.trapmf(_intrusion_level_fuzzy.universe, [70, 85,100,100])\n",
        "_intrusion_level_fuzzy.view()\n",
        "\n",
        "# Aturan fuzzy\n",
        "_rules_fuzzy = [\n",
        "    ctrl.Rule(_duration_fuzzy['low'] & _src_bytes_fuzzy['low'] & _dst_bytes_fuzzy['low'] & _count_fuzzy['low'] & _serror_rate_fuzzy['low'], _intrusion_level_fuzzy['normal']),\n",
        "    ctrl.Rule(_duration_fuzzy['high'] | _src_bytes_fuzzy['high'] | _dst_bytes_fuzzy['high'], _intrusion_level_fuzzy['intrusion']),\n",
        "    ctrl.Rule(_count_fuzzy['high'] & _serror_rate_fuzzy['high'], _intrusion_level_fuzzy['intrusion']),\n",
        "    ctrl.Rule(_duration_fuzzy['medium'] & _src_bytes_fuzzy['medium'] & _dst_bytes_fuzzy['medium'] & _count_fuzzy['medium'] & _serror_rate_fuzzy['medium'], _intrusion_level_fuzzy['suspicious']),\n",
        "    ctrl.Rule(_serror_rate_fuzzy['high'], _intrusion_level_fuzzy['intrusion']),\n",
        "    ctrl.Rule(_duration_fuzzy['high'] & _count_fuzzy['high'], _intrusion_level_fuzzy['intrusion']),\n",
        "    ctrl.Rule(_src_bytes_fuzzy['high'] & _dst_bytes_fuzzy['low'], _intrusion_level_fuzzy['suspicious']),\n",
        "    ctrl.Rule(_dst_bytes_fuzzy['high'] & _src_bytes_fuzzy['low'], _intrusion_level_fuzzy['suspicious']),\n",
        "    ctrl.Rule(_count_fuzzy['medium'] & _serror_rate_fuzzy['high'], _intrusion_level_fuzzy['intrusion']),\n",
        "    ctrl.Rule(_duration_fuzzy['low'] & _count_fuzzy['high'], _intrusion_level_fuzzy['suspicious'])\n",
        "]\n",
        "\n",
        "_fuzzy_ctrl_system = ctrl.ControlSystem(_rules_fuzzy)\n",
        "_fuzzy_sim = ctrl.ControlSystemSimulation(_fuzzy_ctrl_system)\n",
        "\n",
        "_fuzzy_scores_fuzzy = []\n",
        "_predictions_fuzzy = []\n",
        "_binary_preds_fuzzy = []\n",
        "\n",
        "for _, _row_fuzzy in _X_fuzzy_norm.iterrows():\n",
        "    try:\n",
        "        _fuzzy_sim.input['duration']         = _row_fuzzy['duration']\n",
        "        _fuzzy_sim.input['src_bytes']        = _row_fuzzy['src_bytes']\n",
        "        _fuzzy_sim.input['dst_bytes']        = _row_fuzzy['dst_bytes']\n",
        "        _fuzzy_sim.input['count']            = _row_fuzzy['count']\n",
        "        _fuzzy_sim.input['serror_rate_fuzzy']= _row_fuzzy['serror_rate_fuzzy']\n",
        "        _fuzzy_sim.compute()\n",
        "        _score_out = _fuzzy_sim.output['intrusion_level_fuzzy']\n",
        "        _fuzzy_scores_fuzzy.append(_score_out)\n",
        "        if _score_out <= 30:\n",
        "            _pred_fuzzy = 'Normal'\n",
        "        elif _score_out <= 60:\n",
        "            _pred_fuzzy = 'Probe'\n",
        "        elif _score_out <= 80:\n",
        "            _pred_fuzzy = 'R2L'\n",
        "        else:\n",
        "            _pred_fuzzy = 'DoS' if _row_fuzzy['dst_bytes'] > 0.5 else 'U2R'\n",
        "        _predictions_fuzzy.append(_pred_fuzzy)\n",
        "        _binary_preds_fuzzy.append(0 if _pred_fuzzy == 'Normal' else 1)\n",
        "    except Exception:\n",
        "        _fuzzy_scores_fuzzy.append(0)\n",
        "        _predictions_fuzzy.append('Normal')\n",
        "        _binary_preds_fuzzy.append(0)\n",
        "_intrusion_level_fuzzy.view(sim=_fuzzy_sim)\n",
        "# Simpan hasil prediksi\n",
        "_df_sample_fuzzy['fuzzy_score_fuzzy']       = _fuzzy_scores_fuzzy\n",
        "_df_sample_fuzzy['multi_prediction_fuzzy']  = _predictions_fuzzy\n",
        "_df_sample_fuzzy['binary_prediction_fuzzy'] = _binary_preds_fuzzy\n",
        "\n",
        "# Confusion Matrix - Biner Keseluruhan\n",
        "_binary_true_fuzzy = [0 if p == 'Normal' else 1 for p in _df_sample_fuzzy['multi_prediction_fuzzy']]\n",
        "_cm_bin_all_fuzzy = confusion_matrix(_binary_true_fuzzy, _binary_preds_fuzzy)\n",
        "plt.figure(figsize=(5, 4))\n",
        "sns.heatmap(_cm_bin_all_fuzzy, annot=True, fmt='d', cmap='PuBu', xticklabels=['Normal', 'Intrusion'], yticklabels=['Normal', 'Intrusion'])\n",
        "plt.title(\"Confusion Matrix - Fuzzy Biner (Keseluruhan)\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Confusion Matrix - Biner Training\n",
        "_train_bin_true_fuzzy = [0 if _df_sample_fuzzy.loc[i, 'multi_prediction_fuzzy'] == 'Normal' else 1 for i in _idx_train_fuzzy]\n",
        "_train_bin_pred_fuzzy = [_binary_preds_fuzzy[i] for i in _idx_train_fuzzy]\n",
        "_cm_bin_train_fuzzy = confusion_matrix(_train_bin_true_fuzzy, _train_bin_pred_fuzzy)\n",
        "plt.figure(figsize=(5, 4))\n",
        "sns.heatmap(_cm_bin_train_fuzzy, annot=True, fmt='d', cmap='Oranges', xticklabels=['Normal', 'Intrusion'], yticklabels=['Normal', 'Intrusion'])\n",
        "plt.title(\"Confusion Matrix - Fuzzy Biner (Training)\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Confusion Matrix - Biner Testing\n",
        "_test_bin_true_fuzzy = [0 if _df_sample_fuzzy.loc[i, 'multi_prediction_fuzzy'] == 'Normal' else 1 for i in _idx_test_fuzzy]\n",
        "_test_bin_pred_fuzzy = [_binary_preds_fuzzy[i] for i in _idx_test_fuzzy]\n",
        "_cm_bin_test_fuzzy = confusion_matrix(_test_bin_true_fuzzy, _test_bin_pred_fuzzy)\n",
        "plt.figure(figsize=(5, 4))\n",
        "sns.heatmap(_cm_bin_test_fuzzy, annot=True, fmt='d', cmap='Blues', xticklabels=['Normal', 'Intrusion'], yticklabels=['Normal', 'Intrusion'])\n",
        "plt.title(\"Confusion Matrix - Fuzzy Biner (Testing)\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Confusion Matrix - Multi-Kelas Training\n",
        "_train_true_fuzzy = _df_sample_fuzzy.loc[_idx_train_fuzzy, 'multi_prediction_fuzzy']\n",
        "_train_pred_fuzzy = pd.Series(_predictions_fuzzy, index=_df_sample_fuzzy.index).loc[_idx_train_fuzzy]\n",
        "_cm_train_fuzzy = confusion_matrix(_train_true_fuzzy, _train_pred_fuzzy, labels=['Normal', 'Probe', 'R2L', 'DoS', 'U2R'])\n",
        "plt.figure(figsize=(6, 5))\n",
        "sns.heatmap(_cm_train_fuzzy, annot=True, fmt='d', cmap='Oranges', xticklabels=['Normal', 'Probe', 'R2L', 'DoS', 'U2R'], yticklabels=['Normal', 'Probe', 'R2L', 'DoS', 'U2R'])\n",
        "plt.title(\"Confusion Matrix - Fuzzy Training\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Confusion Matrix - Multi-Kelas Testing\n",
        "_test_true_fuzzy = _df_sample_fuzzy.loc[_idx_test_fuzzy, 'multi_prediction_fuzzy']\n",
        "_test_pred_fuzzy = pd.Series(_predictions_fuzzy, index=_df_sample_fuzzy.index).loc[_idx_test_fuzzy]\n",
        "_cm_test_fuzzy = confusion_matrix(_test_true_fuzzy, _test_pred_fuzzy, labels=['Normal', 'Probe', 'R2L', 'DoS', 'U2R'])\n",
        "plt.figure(figsize=(6, 5))\n",
        "sns.heatmap(_cm_test_fuzzy, annot=True, fmt='d', cmap='Blues', xticklabels=['Normal', 'Probe', 'R2L', 'DoS', 'U2R'], yticklabels=['Normal', 'Probe', 'R2L', 'DoS', 'U2R'])\n",
        "plt.title(\"Confusion Matrix - Fuzzy Testing\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Confusion Matrix - Multi-Kelas Keseluruhan\n",
        "_cm_all_fuzzy = confusion_matrix(_df_sample_fuzzy['multi_prediction_fuzzy'], _predictions_fuzzy, labels=['Normal', 'Probe', 'R2L', 'DoS', 'U2R'])\n",
        "plt.figure(figsize=(6, 5))\n",
        "sns.heatmap(_cm_all_fuzzy, annot=True, fmt='d', cmap='Greens', xticklabels=['Normal', 'Probe', 'R2L', 'DoS', 'U2R'], yticklabels=['Normal', 'Probe', 'R2L', 'DoS', 'U2R'])\n",
        "plt.title(\"Confusion Matrix - Fuzzy Keseluruhan\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Distribusi skor fuzzy per subset\n",
        "plt.figure(figsize=(8, 4))\n",
        "plt.hist(_df_sample_fuzzy.loc[_idx_train_fuzzy, 'fuzzy_score_fuzzy'], bins=20, alpha=0.6, label='Train', color='orange')\n",
        "plt.hist(_df_sample_fuzzy.loc[_idx_test_fuzzy,  'fuzzy_score_fuzzy'], bins=20, alpha=0.6, label='Test',  color='blue')\n",
        "plt.hist(_df_sample_fuzzy['fuzzy_score_fuzzy'], bins=20, alpha=0.4, label='All',   color='green')\n",
        "plt.title(\"Distribusi Skor Fuzzy (Train/Test/All)\")\n",
        "plt.xlabel(\"Fuzzy Score\")\n",
        "plt.ylabel(\"Jumlah\")\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Create block diagram for fuzzy classification pipeline\n",
        "fig, ax = plt.subplots(figsize=(10, 3))\n",
        "ax.set_axis_off()\n",
        "\n",
        "# Define block positions and labels\n",
        "blocks = [\n",
        "    (\"Fitur\\nInput\", 0.1),\n",
        "    (\"Fuzzifikasi\", 0.3),\n",
        "    (\"Inferensi\\nEngine\", 0.5),\n",
        "    (\"Defuzzifikasi\", 0.7),\n",
        "    (\"Klasifikasi\\nOutput\", 0.9),\n",
        "]\n",
        "\n",
        "# Draw blocks and arrows\n",
        "width, height = 0.15, 0.2\n",
        "for label, x in blocks:\n",
        "    rect = Rectangle((x - width/2, 0.4), width, height, fill=False)\n",
        "    ax.add_patch(rect)\n",
        "    ax.text(x, 0.5, label, ha='center', va='center')\n",
        "# Draw arrows between blocks\n",
        "for i in range(len(blocks) - 1):\n",
        "    x_start = blocks[i][1] + width/2\n",
        "    x_end = blocks[i+1][1] - width/2\n",
        "    ax.annotate(\"\",\n",
        "                xy=(x_end, 0.5), xytext=(x_start, 0.5),\n",
        "                arrowprops=dict(arrowstyle='->'))\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "# Evaluasi metrik\n",
        "_binary_true_fuzzy = [0 if p == 'Normal' else 1 for p in _df_sample_fuzzy['multi_prediction_fuzzy']]\n",
        "_acc_fuzzy   = accuracy_score(_binary_true_fuzzy, _binary_preds_fuzzy)\n",
        "_prec_fuzzy  = precision_score(_binary_true_fuzzy, _binary_preds_fuzzy, zero_division=0)\n",
        "_rec_fuzzy   = recall_score(_binary_true_fuzzy, _binary_preds_fuzzy, zero_division=0)\n",
        "_f1_fuzzy    = f1_score(_binary_true_fuzzy, _binary_preds_fuzzy, zero_division=0)\n",
        "print(f\"\\n=== Evaluasi Fuzzy (Biner) ===\")\n",
        "print(f\"Akurasi  : {_acc_fuzzy:.4f}\")\n",
        "print(f\"Precision: {_prec_fuzzy:.4f}\")\n",
        "print(f\"Recall   : {_rec_fuzzy:.4f}\")\n",
        "print(f\"F1-Score : {_f1_fuzzy:.4f}\")\n",
        "\n",
        "# Evaluasi multi-kelas\n",
        "_multi_true_fuzzy = _df_sample_fuzzy['multi_prediction_fuzzy']\n",
        "_multi_pred_fuzzy = _predictions_fuzzy\n",
        "print(\"\\n=== Evaluasi Fuzzy (Multi-Kelas) ===\")\n",
        "print(classification_report(_multi_true_fuzzy, _multi_pred_fuzzy, zero_division=0))\n",
        "\n",
        "# Tampilkan beberapa fuzzy scores\n",
        "print(\"\\n=== Contoh Fuzzy Scores ===\")\n",
        "print(_df_sample_fuzzy['fuzzy_score_fuzzy'].head(10).to_list())\n",
        "\n",
        "# Augmentasi Data dan Wilcoxon Test (dengan noise ringan)\n",
        "_df_aug_fuzzy = _df_sample_fuzzy.copy()\n",
        "# Pastikan src_bytes float sebelum noise\n",
        "_df_aug_fuzzy['src_bytes'] = _df_aug_fuzzy['src_bytes'].astype(float)\n",
        "_indices_aug_fuzzy = np.random.choice(_df_aug_fuzzy.index, size=int(0.05 * len(_df_aug_fuzzy)), replace=False)\n",
        "_df_aug_fuzzy.loc[_indices_aug_fuzzy, 'src_bytes'] += np.random.normal(loc=0, scale=10, size=len(_indices_aug_fuzzy))\n",
        "print(f\"\\nData dimodifikasi secara acak pada {len(_indices_aug_fuzzy)} baris (augmentasi dengan noise ringan)\")\n",
        "\n",
        "_original_fuzzy = _df_sample_fuzzy.loc[_indices_aug_fuzzy, 'src_bytes']\n",
        "_augmented_fuzzy = _df_aug_fuzzy.loc[_indices_aug_fuzzy, 'src_bytes']\n",
        "if len(_original_fuzzy) == len(_augmented_fuzzy):\n",
        "    _stat_fuzzy, _p_fuzzy = wilcoxon(_original_fuzzy, _augmented_fuzzy)\n",
        "    print(f\"\\nWilcoxon test untuk src_bytes: statistic = {_stat_fuzzy:.4f}, p-value = {_p_fuzzy:.4f}\")\n",
        "else:\n",
        "    print(\"\\nTidak cukup data sepadan untuk Wilcoxon test.\")\n",
        "\n",
        "def run_fuzzy_cv(df, fuzzy_sys, bounds, n_splits=5):\n",
        "    from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "    all_scores = []\n",
        "    start_time = time.time()\n",
        "\n",
        "    for train_i, test_i in skf.split(df, df['binary_label']):\n",
        "        sub = df.iloc[test_i]\n",
        "        for _, row in sub.iterrows():\n",
        "            sim = ctrl.ControlSystemSimulation(fuzzy_sys)\n",
        "            for feat in bounds:\n",
        "                sim.input[feat] = row[feat]\n",
        "            sim.compute()\n",
        "            score = sim.output['intrusion']\n",
        "            all_scores.append(score)\n",
        "\n",
        "    end_time = time.time()\n",
        "    elapsed = end_time - start_time\n",
        "    return np.array(all_scores), elapsed\n"
      ],
      "metadata": {
        "id": "YNjMFrF3zRCP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        },
        "outputId": "9c3f2de6-8d14-4235-da2f-dfdcb46a69c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'skfuzzy'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-786ebde01b5f>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mskfuzzy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfuzz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mskfuzzy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcontrol\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mctrl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMinMaxScaler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'skfuzzy'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "FUZZY SUGENO"
      ],
      "metadata": {
        "id": "UiMPXtOwUGd2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Load data dan preprocessing\n",
        "_df_fuzzy = pd.read_csv('D:/MATERI KULIAH/Semester 4/Dasar Kecerdasan Artifisial/Tubes/Test_data.csv/Test_data.csv')\n",
        "_df_fuzzy.replace('?', np.nan, inplace=True)\n",
        "_df_fuzzy.dropna(inplace=True)\n",
        "\n",
        "# Pastikan kolom serror_rate_fuzzy ada\n",
        "if 'serror_rate' not in _df_fuzzy.columns:\n",
        "    if 'dst_host_serror_rate' in _df_fuzzy.columns:\n",
        "        _df_fuzzy['serror_rate_fuzzy'] = _df_fuzzy['dst_host_serror_rate']\n",
        "    else:\n",
        "        _df_fuzzy['serror_rate_fuzzy'] = 0.0\n",
        "else:\n",
        "    _df_fuzzy['serror_rate_fuzzy'] = _df_fuzzy['serror_rate']\n",
        "\n",
        "# Sampling data\n",
        "_df_sample_fuzzy = _df_fuzzy.sample(n=1000, random_state=42).reset_index(drop=True)\n",
        "\n",
        "# Normalisasi fitur\n",
        "_features_fuzzy = ['duration', 'src_bytes', 'dst_bytes', 'count', 'serror_rate_fuzzy']\n",
        "_scaler = MinMaxScaler()\n",
        "_X_fuzzy_norm = pd.DataFrame(_scaler.fit_transform(_df_sample_fuzzy[_features_fuzzy]), columns=_features_fuzzy)\n",
        "\n",
        "# Membership function params untuk Sugeno (trimf/trapmf)\n",
        "mf_params = {\n",
        "    'duration': {\n",
        "        'low':    ([0, 0, 0.1], 'trimf'),\n",
        "        'medium': ([0.05, 0.25, 0.5], 'trimf'),\n",
        "        'high':   ([0.4, 0.7, 1, 1], 'trapmf'),\n",
        "    },\n",
        "    'src_bytes': {\n",
        "        'low':    ([0, 0, 0.2], 'trimf'),\n",
        "        'medium': ([0.1, 0.4, 0.7], 'trimf'),\n",
        "        'high':   ([0.6, 0.8, 1, 1], 'trapmf'),\n",
        "    },\n",
        "    'dst_bytes': {\n",
        "        'low':    ([0, 0, 0.2], 'trimf'),\n",
        "        'medium': ([0.1, 0.5, 0.8], 'trimf'),\n",
        "        'high':   ([0.7, 0.9, 1, 1], 'trapmf'),\n",
        "    },\n",
        "    'count': {\n",
        "        'low':    ([0, 0, 0.3], 'trimf'),\n",
        "        'medium': ([0.2, 0.6, 0.85], 'trimf'),\n",
        "        'high':   ([0.75, 0.9, 1, 1], 'trapmf'),\n",
        "    },\n",
        "    'serror_rate_fuzzy': {\n",
        "        'low':    ([0, 0, 0.1], 'trimf'),\n",
        "        'medium': ([0.05, 0.4, 0.7], 'trimf'),\n",
        "        'high':   ([0.6, 0.8, 1, 1], 'trapmf'),\n",
        "    }\n",
        "}\n",
        "\n",
        "def plot_mf(feature_name, mf_dict):\n",
        "    x = np.linspace(0, 1, 1000)\n",
        "    plt.figure(figsize=(6,4))\n",
        "    for label, (params, mf_type) in mf_dict.items():\n",
        "        if mf_type == 'trimf':\n",
        "            a,b,c = params\n",
        "            y = np.piecewise(x,\n",
        "                             [x <= a, (a < x) & (x <= b), (b < x) & (x < c), x >= c],\n",
        "                             [0,\n",
        "                              lambda x: (x - a)/(b - a) if (b - a) > 0 else 0,\n",
        "                              lambda x: (c - x)/(c - b) if (c - b) > 0 else 0,\n",
        "                              0])\n",
        "        elif mf_type == 'trapmf':\n",
        "            a,b,c,d = params\n",
        "            y = np.piecewise(x,\n",
        "                             [x <= a, (a < x) & (x <= b), (b < x) & (x <= c), (c < x) & (x < d), x >= d],\n",
        "                             [0,\n",
        "                              lambda x: (x - a)/(b - a) if (b - a) > 0 else 0,\n",
        "                              1,\n",
        "                              lambda x: (d - x)/(d - c) if (d - c) > 0 else 0,\n",
        "                              0])\n",
        "        else:\n",
        "            y = np.zeros_like(x)\n",
        "        plt.plot(x, y, label=label)\n",
        "    plt.title(f'Fungsi Keanggotaan Fitur \"{feature_name}\"')\n",
        "    plt.xlabel('Nilai Normalisasi')\n",
        "    plt.ylabel('Derajat Keanggotaan')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "# Plot semua fitur\n",
        "for feat in mf_params:\n",
        "    plot_mf(feat, mf_params[feat])\n",
        "\n",
        "# Output konstanta rule Sugeno\n",
        "output_constants = {\n",
        "    'normal': 10,\n",
        "    'suspicious': 50,\n",
        "    'intrusion': 90,\n",
        "}\n",
        "\n",
        "x = np.linspace(0, 100, 500)\n",
        "\n",
        "# Membership fungsi output Sugeno sebagai fungsi \"step\" / trapezoid dengan nilai konstan\n",
        "def sugeno_mf(x, center, width=20):\n",
        "    # Fungsi membership trapezoid yang naik dan turun secara linear sekitar center\n",
        "    left = center - width/2\n",
        "    right = center + width/2\n",
        "    y = np.piecewise(x,\n",
        "                     [x < left, (x >= left) & (x <= right), x > right],\n",
        "                     [0, 1, 0])\n",
        "    return y\n",
        "\n",
        "plt.figure(figsize=(7,4))\n",
        "plt.plot(x, sugeno_mf(x, output_constants['normal']), label='normal')\n",
        "plt.plot(x, sugeno_mf(x, output_constants['suspicious']), label='suspicious')\n",
        "plt.plot(x, sugeno_mf(x, output_constants['intrusion']), label='intrusion')\n",
        "\n",
        "plt.fill_between(x, 0, sugeno_mf(x, output_constants['normal']), alpha=0.3)\n",
        "plt.fill_between(x, 0, sugeno_mf(x, output_constants['suspicious']), alpha=0.3)\n",
        "plt.fill_between(x, 0, sugeno_mf(x, output_constants['intrusion']), alpha=0.3)\n",
        "\n",
        "plt.title('Fungsi Keanggotaan Output Fuzzy Sugeno (Konstanta)')\n",
        "plt.xlabel('intrusion_level_fuzzy')\n",
        "plt.ylabel('Membership')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Rules fuzzy Sugeno (antecedent -> consequent)\n",
        "rules = [\n",
        "    ({'duration':'low', 'src_bytes':'low', 'dst_bytes':'low', 'count':'low', 'serror_rate_fuzzy':'low'}, 'normal'),\n",
        "    ({'duration':'high'}, 'intrusion'),\n",
        "    ({'src_bytes':'high'}, 'intrusion'),\n",
        "    ({'dst_bytes':'high'}, 'intrusion'),\n",
        "    ({'count':'high', 'serror_rate_fuzzy':'high'}, 'intrusion'),\n",
        "    ({'duration':'medium', 'src_bytes':'medium', 'dst_bytes':'medium', 'count':'medium', 'serror_rate_fuzzy':'medium'}, 'suspicious'),\n",
        "    ({'serror_rate_fuzzy':'high'}, 'intrusion'),\n",
        "    ({'duration':'high', 'count':'high'}, 'intrusion'),\n",
        "    ({'src_bytes':'high', 'dst_bytes':'low'}, 'suspicious'),\n",
        "    ({'dst_bytes':'high', 'src_bytes':'low'}, 'suspicious'),\n",
        "    ({'count':'medium', 'serror_rate_fuzzy':'high'}, 'intrusion'),\n",
        "    ({'duration':'low', 'count':'high'}, 'suspicious'),\n",
        "]\n",
        "\n",
        "\n",
        "\n",
        "# Fungsi hitung membership degree\n",
        "def membership_degree(x, params, mf_type='trimf'):\n",
        "    if mf_type == 'trimf':\n",
        "        a,b,c = params\n",
        "        if x <= a or x >= c:\n",
        "            return 0\n",
        "        elif a < x <= b:\n",
        "            return (x - a) / (b - a) if b!=a else 0\n",
        "        elif b < x < c:\n",
        "            return (c - x) / (c - b) if c!=b else 0\n",
        "        else:\n",
        "            return 0\n",
        "    elif mf_type == 'trapmf':\n",
        "        a,b,c,d = params\n",
        "        if x <= a or x >= d:\n",
        "            return 0\n",
        "        elif a < x <= b:\n",
        "            return (x - a) / (b - a) if b!=a else 0\n",
        "        elif b < x <= c:\n",
        "            return 1\n",
        "        elif c < x < d:\n",
        "            return (d - x) / (d - c) if d!=c else 0\n",
        "        else:\n",
        "            return 0\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "# Fungsi hitung firing strength rule\n",
        "def rule_firing_strength(sample, conds):\n",
        "    degrees = []\n",
        "    for feat, lbl in conds.items():\n",
        "        deg = membership_degree(sample[feat], mf_params[feat][lbl][0], mf_params[feat][lbl][1])\n",
        "        degrees.append(deg)\n",
        "    return min(degrees) if degrees else 0\n",
        "\n",
        "# Fungsi inferensi Sugeno (weighted average)\n",
        "def infer_sugeno(sample):\n",
        "    strengths = []\n",
        "    outputs = []\n",
        "    for conds, out_label in rules:\n",
        "        strength = rule_firing_strength(sample, conds)\n",
        "        strengths.append(strength)\n",
        "        outputs.append(output_constants[out_label])\n",
        "    if sum(strengths) == 0:\n",
        "        return 0\n",
        "    return sum(s*o for s,o in zip(strengths, outputs)) / sum(strengths)\n",
        "\n",
        "def plot_confusion_matrices(true_labels, preds, title_prefix='Sugeno'):\n",
        "    from sklearn.metrics import confusion_matrix\n",
        "\n",
        "    # Binary Confusion Matrix\n",
        "    binary_true = [0 if l == 'Normal' else 1 for l in true_labels]\n",
        "    binary_pred = [0 if p == 'Normal' else 1 for p in preds]\n",
        "    cm_bin = confusion_matrix(binary_true, binary_pred)\n",
        "    plt.figure(figsize=(5, 4))\n",
        "    sns.heatmap(cm_bin, annot=True, fmt='d', cmap='PuBu', xticklabels=['Normal', 'Intrusion'], yticklabels=['Normal', 'Intrusion'])\n",
        "    plt.title(f'Confusion Matrix - {title_prefix} Biner')\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('Actual')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # Multi-class Confusion Matrix\n",
        "    labels_order = ['Normal', 'Probe', 'R2L', 'DoS', 'U2R']\n",
        "    cm_multi = confusion_matrix(true_labels, preds, labels=labels_order)\n",
        "    plt.figure(figsize=(6, 5))\n",
        "    sns.heatmap(cm_multi, annot=True, fmt='d', cmap='Greens', xticklabels=labels_order, yticklabels=labels_order)\n",
        "    plt.title(f'Confusion Matrix - {title_prefix} Multi-Kelas')\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('Actual')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# Inferensi dan klasifikasi\n",
        "scores = []\n",
        "preds = []\n",
        "for _, row in _X_fuzzy_norm.iterrows():\n",
        "    score = infer_sugeno(row)\n",
        "    scores.append(score)\n",
        "    if score <= 30:\n",
        "        pred = 'Normal'\n",
        "    elif score <= 60:\n",
        "        pred = 'Probe'\n",
        "    elif score <= 80:\n",
        "        pred = 'R2L'\n",
        "    else:\n",
        "        pred = 'DoS' if row['dst_bytes'] > 0.5 else 'U2R'\n",
        "    preds.append(pred)\n",
        "\n",
        "_df_sample_fuzzy['sugeno_score'] = scores\n",
        "_df_sample_fuzzy['sugeno_prediction'] = preds\n",
        "\n",
        "# Tampilkan hasil prediksi dan distribusi skor\n",
        "plt.figure(figsize=(8,4))\n",
        "plt.hist(_df_sample_fuzzy.loc[_idx_train_fuzzy, 'sugeno_score'], bins=20, alpha=0.6, label='Train', color='orange')\n",
        "plt.hist(_df_sample_fuzzy.loc[_idx_test_fuzzy, 'sugeno_score'], bins=20, alpha=0.6, label='Test', color='blue')\n",
        "plt.hist(_df_sample_fuzzy['sugeno_score'], bins=20, alpha=0.4, label='All', color='green')\n",
        "plt.title(\"Distribusi Skor Fuzzy Sugeno (Train/Test/All)\")\n",
        "plt.xlabel(\"Fuzzy Score\")\n",
        "plt.ylabel(\"Jumlah\")\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Jika ada kolom label di dataset, lakukan evaluasi\n",
        "if 'label' in _df_sample_fuzzy.columns:\n",
        "    true_labels = _df_sample_fuzzy['label'].str.strip().str.lower().str.rstrip('.').map({\n",
        "        'normal': 'Normal', 'dos': 'DoS', 'probe': 'Probe', 'r2l': 'R2L', 'u2r': 'U2R'\n",
        "    }).fillna(_df_sample_fuzzy['label'])\n",
        "\n",
        "    plot_confusion_matrices(true_labels, preds, title_prefix='Sugeno')\n",
        "\n",
        "    print(\"=== Evaluasi Sugeno (Biner) ===\")\n",
        "    print(f\"Akurasi  : {accuracy_score(binary_true, binary_pred):.4f}\")\n",
        "    print(f\"Precision: {precision_score(binary_true, binary_pred, zero_division=0):.4f}\")\n",
        "    print(f\"Recall   : {recall_score(binary_true, binary_pred, zero_division=0):.4f}\")\n",
        "    print(f\"F1-Score : {f1_score(binary_true, binary_pred, zero_division=0):.4f}\")\n",
        "\n",
        "    print(\"\\n=== Evaluasi Sugeno (Multi-Kelas) ===\")\n",
        "    print(classification_report(true_labels, preds, zero_division=0))\n",
        "\n",
        "else:\n",
        "    print(\"Kolom 'label' tidak ditemukan di dataset, evaluasi metrik tidak dapat dilakukan.\")\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10,3))\n",
        "ax.set_axis_off()\n",
        "blocks = [\n",
        "    (\"Fitur\\nInput\", 0.1),\n",
        "    (\"Fuzzifikasi\", 0.3),\n",
        "    (\"Inferensi\\nEngine\", 0.5),\n",
        "    (\"Defuzzifikasi\", 0.7),\n",
        "    (\"Klasifikasi\\nOutput\", 0.9),\n",
        "]\n",
        "width, height = 0.15, 0.2\n",
        "for label, x in blocks:\n",
        "    rect = Rectangle((x - width/2, 0.4), width, height, fill=False)\n",
        "    ax.add_patch(rect)\n",
        "    ax.text(x, 0.5, label, ha='center', va='center')\n",
        "for i in range(len(blocks) - 1):\n",
        "    x_start = blocks[i][1] + width/2\n",
        "    x_end = blocks[i+1][1] - width/2\n",
        "    ax.annotate(\"\", xy=(x_end, 0.5), xytext=(x_start, 0.5), arrowprops=dict(arrowstyle='->'))\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Wilcoxon test dengan augmentasi noise ringan pada fitur src_bytes\n",
        "_df_aug_fuzzy = _df_sample_fuzzy.copy()\n",
        "_df_aug_fuzzy['src_bytes'] = _df_aug_fuzzy['src_bytes'].astype(float)\n",
        "_indices_aug_fuzzy = np.random.choice(_df_aug_fuzzy.index, size=int(0.05 * len(_df_aug_fuzzy)), replace=False)\n",
        "_df_aug_fuzzy.loc[_indices_aug_fuzzy, 'src_bytes'] += np.random.normal(loc=0, scale=10, size=len(_indices_aug_fuzzy))\n",
        "\n",
        "_original_fuzzy = _df_sample_fuzzy.loc[_indices_aug_fuzzy, 'src_bytes']\n",
        "_augmented_fuzzy = _df_aug_fuzzy.loc[_indices_aug_fuzzy, 'src_bytes']\n",
        "\n",
        "if len(_original_fuzzy) == len(_augmented_fuzzy):\n",
        "    stat_wilcoxon, p_wilcoxon = wilcoxon(_original_fuzzy, _augmented_fuzzy)\n",
        "    print(f\"\\nWilcoxon test untuk src_bytes: statistic = {stat_wilcoxon:.4f}, p-value = {p_wilcoxon:.4f}\")\n",
        "else:\n",
        "    print(\"\\nTidak cukup data sepadan untuk Wilcoxon test.\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "1hBxeTMoUKYC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "PERBANDINGAN KNN vs FUZZY (Mamdani dan Sugeno)\n"
      ],
      "metadata": {
        "id": "Z4ishufDIdvE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import skfuzzy as fuzz\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "from skfuzzy import control as ctrl\n",
        "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score, f1_score,\n",
        "    precision_recall_fscore_support\n",
        ")\n",
        "\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# 1) Load & clean original data\n",
        "# -----------------------------------------------------------------------------\n",
        "df_orig = pd.read_csv('D:/Telkom/Semester 4/DKA/tubes/Test_data.csv')\n",
        "df_orig.replace('?', np.nan, inplace=True)\n",
        "df_orig.dropna(inplace=True)\n",
        "\n",
        "# Add serror_rate_fuzzy for fuzzy pipeline\n",
        "if 'serror_rate' in df_orig.columns:\n",
        "    df_orig['serror_rate_fuzzy'] = df_orig['serror_rate']\n",
        "elif 'dst_host_serror_rate' in df_orig.columns:\n",
        "    df_orig['serror_rate_fuzzy'] = df_orig['dst_host_serror_rate']\n",
        "else:\n",
        "    df_orig['serror_rate_fuzzy'] = 0.0\n",
        "\n",
        "# Sample 1000 rows for fair comparison\n",
        "df_orig = df_orig.sample(1000, random_state=42).reset_index(drop=True)\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# 2) Compute ground-truth labels using fuzzy features\n",
        "# -----------------------------------------------------------------------------\n",
        "fz_feats = ['duration','src_bytes','dst_bytes','count','serror_rate_fuzzy']\n",
        "df_orig[fz_feats] = MinMaxScaler().fit_transform(df_orig[fz_feats])\n",
        "\n",
        "# Score = mean of the 5 features * 100\n",
        "df_orig['score'] = df_orig[fz_feats].mean(axis=1) * 100\n",
        "\n",
        "def classify(score, dst):\n",
        "    if score <= 30:\n",
        "        return 'Normal'\n",
        "    if score <= 60:\n",
        "        return 'Probe'\n",
        "    if score <= 80:\n",
        "        return 'R2L'\n",
        "    return 'DoS' if dst > 0.5 else 'U2R'\n",
        "\n",
        "df_orig['attack_type']  = [classify(s, d) for s, d in zip(df_orig['score'], df_orig['dst_bytes'])]\n",
        "df_orig['binary_label'] = df_orig['attack_type'].map(lambda x: 0 if x=='Normal' else 1)\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# 3) Pipeline A: KNN with Stratified 5-Fold CV\n",
        "# -----------------------------------------------------------------------------\n",
        "# Prepare df_knn so we don't lose serror_rate_fuzzy\n",
        "knn_feats = [\n",
        "    'duration','protocol_type','service','flag',\n",
        "    'src_bytes','dst_bytes','count','srv_count'\n",
        "]\n",
        "df_knn = df_orig[knn_feats + ['binary_label','attack_type']].copy()\n",
        "\n",
        "# Encode categoricals\n",
        "for c in ['protocol_type','service','flag']:\n",
        "    df_knn[c] = LabelEncoder().fit_transform(df_knn[c])\n",
        "\n",
        "# Normalize numeric for KNN\n",
        "knn_num = ['duration','src_bytes','dst_bytes','count','srv_count']\n",
        "df_knn[knn_num] = MinMaxScaler().fit_transform(df_knn[knn_num])\n",
        "\n",
        "X_knn   = df_knn[knn_feats]\n",
        "y_knn_b = df_knn['binary_label']\n",
        "y_knn_m = df_knn['attack_type']\n",
        "\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "knn_bin_metrics, knn_multi_metrics = [], []\n",
        "\n",
        "knn_scores_all = []\n",
        "for train_i, test_i in skf.split(X_knn, y_knn_b):\n",
        "    Xtr, Xte   = X_knn.iloc[train_i], X_knn.iloc[test_i]\n",
        "    ytr_b, yte_b = y_knn_b.iloc[train_i], y_knn_b.iloc[test_i]\n",
        "    ytr_m, yte_m = y_knn_m.iloc[train_i], y_knn_m.iloc[test_i]\n",
        "\n",
        "    # Find best k in 1..10 for this fold\n",
        "    best_k, best_acc = 1, 0\n",
        "    for k in range(1, 11):\n",
        "        model = KNeighborsClassifier(n_neighbors=k).fit(Xtr, ytr_b)\n",
        "        acc = accuracy_score(yte_b, model.predict(Xte))\n",
        "        if acc > best_acc:\n",
        "            best_acc, best_k = acc, k\n",
        "\n",
        "    # Evaluate binary\n",
        "    knn_b = KNeighborsClassifier(n_neighbors=best_k).fit(Xtr, ytr_b)\n",
        "    pred_b = knn_b.predict(Xte)\n",
        "    probs_b = knn_b.predict_proba(Xte)[:,1]\n",
        "    knn_scores_all.extend(probs_b)\n",
        "    knn_bin_metrics.append([\n",
        "        accuracy_score(yte_b, pred_b),\n",
        "        precision_score(yte_b, pred_b, zero_division=0),\n",
        "        recall_score(yte_b, pred_b, zero_division=0),\n",
        "        f1_score(yte_b, pred_b, zero_division=0)\n",
        "    ])\n",
        "\n",
        "    # Evaluate multi-class\n",
        "    knn_m = KNeighborsClassifier(n_neighbors=best_k).fit(Xtr, ytr_m)\n",
        "    pred_m = knn_m.predict(Xte)\n",
        "    prf = precision_recall_fscore_support(yte_m, pred_m, average='macro', zero_division=0)\n",
        "    knn_multi_metrics.append([\n",
        "        accuracy_score(yte_m, pred_m),\n",
        "        prf[0], prf[1], prf[2]\n",
        "    ])\n",
        "\n",
        "knn_bin_mean   = np.array(knn_bin_metrics).mean(axis=0)\n",
        "knn_multi_mean = np.array(knn_multi_metrics).mean(axis=0)\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# 4) Pipeline B: Fuzzy Mamdani with Stratified 5-Fold CV\n",
        "# -----------------------------------------------------------------------------\n",
        "df_fz = df_orig.copy()  # still has serror_rate_fuzzy, score, labels\n",
        "\n",
        "# Define fuzzy input variables\n",
        "bounds = {\n",
        "    'duration':          ([0,0,0.1],   [0.05,0.25,0.5], [0.4,0.7,1,1]),\n",
        "    'src_bytes':         ([0,0,0.2],   [0.1,0.4,0.7],   [0.6,0.8,1,1]),\n",
        "    'dst_bytes':         ([0,0,0.2],   [0.1,0.5,0.8],   [0.7,0.9,1,1]),\n",
        "    'count':             ([0,0,0.3],   [0.2,0.6,0.85],  [0.75,0.9,1,1]),\n",
        "    'serror_rate_fuzzy': ([0,0,0.1],   [0.05,0.4,0.7],  [0.6,0.8,1,1]),\n",
        "}\n",
        "vars_in = {}\n",
        "for feat, (low_mf, med_mf, high_mf) in bounds.items():\n",
        "    var = ctrl.Antecedent(np.linspace(0,1,101), feat)\n",
        "    var['low']    = fuzz.trimf(var.universe,    low_mf)\n",
        "    var['medium'] = fuzz.trimf(var.universe,    med_mf)\n",
        "    var['high']   = fuzz.trapmf(var.universe,   high_mf)\n",
        "    vars_in[feat] = var\n",
        "\n",
        "# Define fuzzy output variable (must match lookup key)\n",
        "out = ctrl.Consequent(np.arange(0,101,1), 'intrusion')\n",
        "out['normal']     = fuzz.trimf(out.universe, [0,0,30])\n",
        "out['suspicious'] = fuzz.trimf(out.universe, [20,50,80])\n",
        "out['intrusion']  = fuzz.trapmf(out.universe, [70,85,100,100])\n",
        "\n",
        "# Fuzzy rules\n",
        "rules = [\n",
        "    ctrl.Rule(vars_in['duration']['low']    &\n",
        "              vars_in['src_bytes']['low']   &\n",
        "              vars_in['dst_bytes']['low']   &\n",
        "              vars_in['count']['low']       &\n",
        "              vars_in['serror_rate_fuzzy']['low'],\n",
        "              out['normal']),\n",
        "    ctrl.Rule(vars_in['duration']['high']   |\n",
        "              vars_in['src_bytes']['high']  |\n",
        "              vars_in['dst_bytes']['high'],\n",
        "              out['intrusion']),\n",
        "    ctrl.Rule(vars_in['count']['high']      &\n",
        "              vars_in['serror_rate_fuzzy']['high'],\n",
        "              out['intrusion']),\n",
        "    ctrl.Rule(vars_in['duration']['medium'] &\n",
        "              vars_in['src_bytes']['medium'] &\n",
        "              vars_in['dst_bytes']['medium'] &\n",
        "              vars_in['count']['medium']     &\n",
        "              vars_in['serror_rate_fuzzy']['medium'],\n",
        "              out['suspicious']),\n",
        "]\n",
        "fuzzy_sys = ctrl.ControlSystem(rules)\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# 4) Pipeline C: Fuzzy Sugeno with Stratified 5-Fold CV\n",
        "# -----------------------------------------------------------------------------\n",
        "vars_in_sugeno = {}\n",
        "for feat, (low_mf, med_mf, high_mf) in bounds.items():\n",
        "    var = ctrl.Antecedent(np.linspace(0,1,101), feat)\n",
        "    var['low']    = fuzz.trimf(var.universe, low_mf)\n",
        "    var['medium'] = fuzz.trimf(var.universe, med_mf)\n",
        "    var['high']   = fuzz.trapmf(var.universe, high_mf)\n",
        "    vars_in_sugeno[feat] = var\n",
        "\n",
        "# Output variable Sugeno - gunakan output konstanta\n",
        "out_sugeno = ctrl.Consequent(np.linspace(0, 100, 101), 'intrusion')\n",
        "out_sugeno['normal']     = fuzz.trimf(out_sugeno.universe, [0, 0, 30])\n",
        "out_sugeno['suspicious'] = fuzz.trimf(out_sugeno.universe, [20, 50, 80])\n",
        "out_sugeno['intrusion']  = fuzz.trapmf(out_sugeno.universe, [70, 85, 100, 100])\n",
        "\n",
        "# Aturan fuzzy Sugeno (samakan dengan rules di kode Sugeno)\n",
        "rules_sugeno = [\n",
        "    ctrl.Rule(vars_in_sugeno['duration']['low']    &\n",
        "              vars_in_sugeno['src_bytes']['low']   &\n",
        "              vars_in_sugeno['dst_bytes']['low']   &\n",
        "              vars_in_sugeno['count']['low']       &\n",
        "              vars_in_sugeno['serror_rate_fuzzy']['low'],\n",
        "              out_sugeno['normal']),\n",
        "    ctrl.Rule(vars_in_sugeno['duration']['high']   |\n",
        "              vars_in_sugeno['src_bytes']['high']  |\n",
        "              vars_in_sugeno['dst_bytes']['high'],\n",
        "              out_sugeno['intrusion']),\n",
        "    ctrl.Rule(vars_in_sugeno['count']['high']      &\n",
        "              vars_in_sugeno['serror_rate_fuzzy']['high'],\n",
        "              out_sugeno['intrusion']),\n",
        "    ctrl.Rule(vars_in_sugeno['duration']['medium'] &\n",
        "              vars_in_sugeno['src_bytes']['medium'] &\n",
        "              vars_in_sugeno['dst_bytes']['medium'] &\n",
        "              vars_in_sugeno['count']['medium']     &\n",
        "              vars_in_sugeno['serror_rate_fuzzy']['medium'],\n",
        "              out_sugeno['suspicious']),\n",
        "]\n",
        "\n",
        "# Buat sistem fuzzy Sugeno\n",
        "fuzzy_sugeno_sys = ctrl.ControlSystem(rules_sugeno)\n",
        "\n",
        "fz_bin_metrics, fz_multi_metrics = [], []\n",
        "fuzzy_scores_all = []\n",
        "for train_i, test_i in skf.split(df_fz, df_fz['binary_label']):\n",
        "    sub = df_fz.iloc[test_i]\n",
        "    yb  = sub['binary_label']\n",
        "    ym  = sub['attack_type']\n",
        "\n",
        "    bin_preds, multi_preds = [], []\n",
        "    for _, row in sub.iterrows():\n",
        "        sim = ctrl.ControlSystemSimulation(fuzzy_sys)\n",
        "        try:\n",
        "            for feat in bounds:\n",
        "                val = row[feat]\n",
        "                if pd.isna(val):\n",
        "                    print(f\"Warning: NaN detected in {feat} at index {row.name}\")\n",
        "                sim.input[feat] = val\n",
        "            sim.compute()\n",
        "\n",
        "\n",
        "            if 'intrusion' not in sim.output:\n",
        "                raise KeyError(\"Output 'intrusion' tidak ditemukan\")\n",
        "            score = sim.output['intrusion']\n",
        "\n",
        "            fuzzy_scores_all.append(score / 100)\n",
        "\n",
        "            bin_preds.append(0 if score <= 30 else 1)\n",
        "            if score <= 30:\n",
        "                multi_preds.append('Normal')\n",
        "            elif score <= 60:\n",
        "                multi_preds.append('Probe')\n",
        "            elif score <= 80:\n",
        "                multi_preds.append('R2L')\n",
        "            else:\n",
        "                multi_preds.append('DoS' if row['dst_bytes'] > 0.5 else 'U2R')\n",
        "\n",
        "        except Exception as e:\n",
        "            bin_preds.append(0)\n",
        "            multi_preds.append('Normal')\n",
        "\n",
        "\n",
        "    # Evaluate this fold\n",
        "    fz_bin_metrics.append([\n",
        "        accuracy_score(yb, bin_preds),\n",
        "        precision_score(yb, bin_preds, zero_division=0),\n",
        "        recall_score(yb, bin_preds, zero_division=0),\n",
        "        f1_score(yb, bin_preds, zero_division=0)\n",
        "    ])\n",
        "    prf = precision_recall_fscore_support(ym, multi_preds, average='macro', zero_division=0)\n",
        "    fz_multi_metrics.append([\n",
        "        accuracy_score(ym, multi_preds),\n",
        "        prf[0], prf[1], prf[2]\n",
        "    ])\n",
        "\n",
        "fz_bin_mean   = np.array(fz_bin_metrics).mean(axis=0)\n",
        "fz_multi_mean = np.array(fz_multi_metrics).mean(axis=0)\n",
        "\n",
        "def evaluate_fuzzy_sugeno_cv(df, fuzzy_sugeno_sys, bounds):\n",
        "    from sklearn.model_selection import StratifiedKFold\n",
        "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "    bin_metrics = []\n",
        "    multi_metrics = []\n",
        "\n",
        "    for train_i, test_i in skf.split(df, df['binary_label']):\n",
        "        sub = df.iloc[test_i]\n",
        "        yb = sub['binary_label']\n",
        "        ym = sub['attack_type']\n",
        "\n",
        "        bin_preds = []\n",
        "        multi_preds = []\n",
        "        for _, row in sub.iterrows():\n",
        "            sim = ctrl.ControlSystemSimulation(fuzzy_sugeno_sys)\n",
        "            try:\n",
        "                for feat in bounds:\n",
        "                    sim.input[feat] = row[feat]\n",
        "                sim.compute()\n",
        "                score = sim.output['intrusion']\n",
        "\n",
        "                bin_preds.append(0 if score <= 30 else 1)\n",
        "                if score <= 30:\n",
        "                    multi_preds.append('Normal')\n",
        "                elif score <= 60:\n",
        "                    multi_preds.append('Probe')\n",
        "                elif score <= 80:\n",
        "                    multi_preds.append('R2L')\n",
        "                else:\n",
        "                    multi_preds.append('DoS' if row['dst_bytes'] > 0.5 else 'U2R')\n",
        "            except Exception:\n",
        "                bin_preds.append(0)\n",
        "                multi_preds.append('Normal')\n",
        "\n",
        "        bin_metrics.append([\n",
        "            accuracy_score(yb, bin_preds),\n",
        "            precision_score(yb, bin_preds, zero_division=0),\n",
        "            recall_score(yb, bin_preds, zero_division=0),\n",
        "            f1_score(yb, bin_preds, zero_division=0)\n",
        "        ])\n",
        "        prf = precision_recall_fscore_support(ym, multi_preds, average='macro', zero_division=0)\n",
        "        multi_metrics.append([\n",
        "            accuracy_score(ym, multi_preds),\n",
        "            prf[0], prf[1], prf[2]\n",
        "        ])\n",
        "\n",
        "    bin_mean = np.array(bin_metrics).mean(axis=0)\n",
        "    multi_mean = np.array(multi_metrics).mean(axis=0)\n",
        "    return bin_mean, multi_mean\n",
        "\n",
        "\n",
        "fz_sugeno_bin_mean, fz_sugeno_multi_mean = evaluate_fuzzy_sugeno_cv(df_fz, fuzzy_sugeno_sys, bounds)\n",
        "\n",
        "\n",
        "def run_knn_cv(X, y):\n",
        "    from time import time\n",
        "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "    scores_all = []\n",
        "    start = time()\n",
        "    for train_i, test_i in skf.split(X, y):\n",
        "        Xtr, Xte = X.iloc[train_i], X.iloc[test_i]\n",
        "        ytr, yte = y.iloc[train_i], y.iloc[test_i]\n",
        "\n",
        "        best_k, best_acc = 1, 0\n",
        "        for k in range(1, 11):\n",
        "            model = KNeighborsClassifier(n_neighbors=k).fit(Xtr, ytr)\n",
        "            acc = accuracy_score(yte, model.predict(Xte))\n",
        "            if acc > best_acc:\n",
        "                best_acc, best_k = acc, k\n",
        "\n",
        "        model = KNeighborsClassifier(n_neighbors=best_k).fit(Xtr, ytr)\n",
        "        probs = model.predict_proba(Xte)[:,1]\n",
        "        scores_all.extend(probs)\n",
        "    elapsed = time() - start\n",
        "    return np.array(scores_all), elapsed\n",
        "\n",
        "def run_fuzzy_cv(df, fuzzy_sys, bounds):\n",
        "    from time import time\n",
        "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "    scores_all = []\n",
        "    start = time()\n",
        "    for train_i, test_i in skf.split(df, df['binary_label']):\n",
        "        sub = df.iloc[test_i]\n",
        "        for _, row in sub.iterrows():\n",
        "            sim = ctrl.ControlSystemSimulation(fuzzy_sys)\n",
        "            try:\n",
        "                for feat in bounds:\n",
        "                    sim.input[feat] = row[feat]\n",
        "                sim.compute()\n",
        "                score = sim.output['intrusion']\n",
        "                scores_all.append(score / 100)\n",
        "            except:\n",
        "                scores_all.append(0)\n",
        "    elapsed = time() - start\n",
        "    return np.array(scores_all), elapsed\n",
        "\n",
        "def run_fuzzy_sugeno_cv(df, fuzzy_sugeno_sys, bounds):\n",
        "    from time import time\n",
        "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "    scores_all = []\n",
        "    start = time()\n",
        "    for train_i, test_i in skf.split(df, df['binary_label']):\n",
        "        sub = df.iloc[test_i]\n",
        "        for _, row in sub.iterrows():\n",
        "            sim = ctrl.ControlSystemSimulation(fuzzy_sugeno_sys)\n",
        "            try:\n",
        "                for feat in bounds:\n",
        "                    sim.input[feat] = row[feat]\n",
        "                sim.compute()\n",
        "                score = sim.output['intrusion']\n",
        "                scores_all.append(score / 100)  # normalisasi 0-1\n",
        "            except Exception:\n",
        "                scores_all.append(0)\n",
        "    elapsed = time() - start\n",
        "    return np.array(scores_all), elapsed\n",
        "\n",
        "\n",
        "\n",
        "knn_scores, knn_time = run_knn_cv(X_knn, y_knn_b)\n",
        "fuzzy_scores, fuzzy_time = run_fuzzy_cv(df_fz, fuzzy_sys, bounds)\n",
        "fuzzy_sugeno_scores, fuzzy_sugeno_time = run_fuzzy_sugeno_cv(df_fz, fuzzy_sugeno_sys, bounds)\n",
        "\n",
        "print(f\"KNN time: {knn_time:.2f}s, mean score: {knn_scores.mean():.4f}\")\n",
        "print(f\"Fuzzy time: {fuzzy_time:.2f}s, mean score: {fuzzy_scores.mean():.4f}\")\n",
        "print(f\"Fuzzy Sugeno time: {fuzzy_sugeno_time:.2f}s, mean score: {fuzzy_sugeno_scores.mean():.4f}\")\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# 5) Print descriptive statistic\n",
        "# -----------------------------------------------------------------------------\n",
        "def print_stats(name, scores):\n",
        "    print(f\"Statistik deskriptif {name}:\")\n",
        "    print(f\"  Mean   : {np.mean(scores):.4f}\")\n",
        "    print(f\"  Std    : {np.std(scores):.4f}\")\n",
        "    print(f\"  Min    : {np.min(scores):.4f}\")\n",
        "    print(f\"  Median : {np.median(scores):.4f}\")\n",
        "    print(f\"  Max    : {np.max(scores):.4f}\")\n",
        "    print()\n",
        "\n",
        "print_stats(\"KNN\", knn_scores)\n",
        "print_stats(\"Fuzzy Mamdani\", fuzzy_scores)\n",
        "print_stats(\"Fuzzy Sugeno\", fuzzy_sugeno_scores)\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# 6) Print comparison of mean 5-fold CV metrics\n",
        "# -----------------------------------------------------------------------------\n",
        "cols = ['Accuracy','Precision','Recall','F1']\n",
        "df_binary = pd.DataFrame(\n",
        "    [knn_bin_mean, fz_bin_mean,fz_sugeno_bin_mean],\n",
        "    index=['KNN','Fuzzy Mamdani', 'Fuzzy Sugeno'],\n",
        "    columns=cols\n",
        ")\n",
        "df_multi = pd.DataFrame(\n",
        "    [knn_multi_mean, fz_multi_mean,fz_sugeno_multi_mean],\n",
        "    index=['KNN','Fuzzy Mamdani', 'Fuzzy Sugeno'],\n",
        "    columns=cols\n",
        ")\n",
        "\n",
        "\n",
        "print(\"== Binary Classification (5-Fold CV Mean) ==\")\n",
        "print(df_binary)\n",
        "print(\"\\n== Multi-Class Classification (5-Fold CV Mean) ==\")\n",
        "print(df_multi)\n",
        "\n",
        "plt.figure(figsize=(14, 6))\n",
        "\n",
        "# Boxplot distribusi skor\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.boxplot([knn_scores, fuzzy_scores, fuzzy_sugeno_scores],\n",
        "            labels=['KNN', 'Fuzzy Mamdani', 'Fuzzy Sugeno'])\n",
        "plt.title('Boxplot Distribusi Skor Prediksi')\n",
        "plt.ylabel('Skor Prediksi')\n",
        "\n",
        "# Histogram distribusi skor berdampingan\n",
        "plt.subplot(1, 2, 2)\n",
        "bins = np.linspace(0, 1, 30)\n",
        "plt.hist(knn_scores, bins=bins, alpha=0.6, label='KNN', edgecolor='black')\n",
        "plt.hist(fuzzy_scores, bins=bins, alpha=0.6, label='Fuzzy Mamdani', edgecolor='black')\n",
        "plt.hist(fuzzy_sugeno_scores, bins=bins, alpha=0.6, label='Fuzzy Sugeno', edgecolor='black')\n",
        "plt.title('Histogram Distribusi Skor Prediksi')\n",
        "plt.xlabel('Skor Prediksi')\n",
        "plt.ylabel('Frekuensi')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "QX1g6UXMIbYj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}